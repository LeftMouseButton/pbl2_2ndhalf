"""
Auto-repair validator for Module 3 JSON outputs.
Validated files are written to data/{graph_name}/json_validated/ (originals left untouched).

Usage:
    python -m src.kg.module4_validate_json.validate_json --data-location data/my_graph
    python -m src.kg.module4_validate_json.validate_json data/my_graph/json
"""

from __future__ import annotations

import argparse
import datetime
import json
import re
import sys
from pathlib import Path
from typing import Any, Dict, List

from src.kg.utils.paths import resolve_base_dir

# ---------------------------------------------------------------------
# Schema loading
# ---------------------------------------------------------------------

SCHEMA_CONFIG: Dict[str, Any] | None = None


def load_schema(schema_path: Path) -> dict:
    """Load and return the JSON schema for validation."""
    try:
        schema_json = json.loads(schema_path.read_text(encoding="utf-8"))
    except FileNotFoundError:
        sys.exit(f"‚ùå Schema file not found at {schema_path}")
    except json.JSONDecodeError as e:
        sys.exit(f"‚ùå Failed to parse schema JSON: {e}")

    if not isinstance(schema_json, dict):
        sys.exit("‚ùå Schema file must contain a JSON object at the root level.")
    return schema_json


def configure_schema(schema_path: Path) -> None:
    """Load schema file into memory."""
    global SCHEMA_CONFIG
    SCHEMA_CONFIG = load_schema(schema_path)


def require_schema_config() -> dict:
    if SCHEMA_CONFIG is None:
        raise RuntimeError("Schema not configured.")
    return SCHEMA_CONFIG


def resolve_schema_path(base_dir: Path, override: str | None) -> Path:
    """Resolve schema path using override ‚Üí data/{graph}/config ‚Üí config_default fallback."""
    if override:
        path = Path(override)
        if not path.exists():
            sys.exit(f"‚ùå Schema file not found at override path: {path}")
        return path

    candidates = [
        base_dir / "config" / "schema_keys.json",
        Path("config_default") / "schema_keys.json",
    ]
    for cand in candidates:
        if cand.exists():
            if cand == candidates[1]:
                print(f"‚ö†Ô∏è  Schema not found in graph config, using fallback {cand}")
            return cand

    sys.exit("‚ùå schema_keys.json not found in graph config or config_default/.")


# ---------------------------------------------------------------------
# Normalization helpers
# ---------------------------------------------------------------------

def _ensure_float(val: Any, default: float = 0.0) -> float:
    try:
        return float(val)
    except Exception:
        return float(default)


def _normalize_value_conf(entry: Any, template: dict) -> dict:
    """
    Normalize an attribute/properties entry to {"value": ..., "confidence": ...}
    using defaults from the schema template.
    """
    default_value = template.get("value", "")
    default_conf = _ensure_float(template.get("confidence", 0.0), 0.0)

    if isinstance(entry, dict):
        return {
            "value": entry.get("value", default_value),
            "confidence": _ensure_float(entry.get("confidence", default_conf), default_conf),
        }

    if entry is None:
        return {"value": default_value, "confidence": default_conf}

    return {"value": entry, "confidence": default_conf}


def _slugify(text: str) -> str:
    """
    Create a slug identifier (lowercase, underscores) suitable for node IDs.
    Mirrors the behavior used elsewhere in the pipeline.
    """
    if not isinstance(text, str):
        text = str(text)
    s = text.strip().lower()
    s = re.sub(r"\s+", "_", s)
    s = s.replace("-", "_")
    s = re.sub(r"[^\w_]+", "", s)
    return s or "unknown"


def _convert_schema_like_to_graph_doc(data: dict) -> dict:
    """
    Transform a schema-like JSON of the form:

        {
          "entities": {
             "vtuber": { "id": {...}, "attributes": {...}, "confidence": ... },
             "agency": { ... },
             ...
          },
          "relationships": {
             "belongs_to": {
                 "source_type": "vtuber",
                 "target_type": "agency",
                 "properties": {...},
                 "confidence": ...
             },
             ...
          }
        }

    into a proper graph-document:

        {
          "entities": [
            { "id": "usada_pekora", "type": "vtuber", "name": "Usada Pekora", ... },
            { "id": "hololive_production", "type": "agency", "name": "Hololive Production", ... },
            ...
          ],
          "relationships": [
            { "source": "usada_pekora", "relation": "belongs_to", "target": "hololive_production", ... },
            ...
          ]
        }

    The relationship edges are generated by connecting all entities of the
    appropriate source/target types, using the per-type relationship schema.
    """
    entities_obj = data.get("entities") or {}
    rels_obj = data.get("relationships") or {}

    if not isinstance(entities_obj, dict) or not isinstance(rels_obj, dict):
        return data

    entities_list: List[Dict[str, Any]] = []

    # Build concrete entities from schema-style definitions
    for node_type, ent_cfg in entities_obj.items():
        if not isinstance(ent_cfg, dict):
            continue

        id_cfg = ent_cfg.get("id") or {}
        attrs_cfg = ent_cfg.get("attributes") or {}
        conf = _ensure_float(ent_cfg.get("confidence"), 0.0)

        raw_id = id_cfg.get("value") if isinstance(id_cfg, dict) else ""
        name_attr = attrs_cfg.get("name") or {}
        raw_name = name_attr.get("value") if isinstance(name_attr, dict) else ""

        base_label = raw_name or raw_id
        slug_id = _slugify(base_label or node_type)

        entity: Dict[str, Any] = {
            "id": slug_id,
            "type": node_type,
            "name": base_label,
            "confidence": conf,
            "attributes": attrs_cfg,
        }
        entities_list.append(entity)

    # Build lookup by type for relationship wiring
    entities_by_type: Dict[str, List[str]] = {}
    for ent in entities_list:
        et = ent.get("type")
        if not et:
            continue
        entities_by_type.setdefault(et, []).append(ent.get("id"))

    relationships_list: List[Dict[str, Any]] = []

    for rel_name, rel_cfg in rels_obj.items():
        if not isinstance(rel_cfg, dict):
            continue
        src_type = rel_cfg.get("source_type")
        tgt_type = rel_cfg.get("target_type")
        if not (src_type and tgt_type):
            continue

        props = rel_cfg.get("properties") or {}
        conf = _ensure_float(rel_cfg.get("confidence"), 0.0)

        src_ids = entities_by_type.get(src_type, [])
        tgt_ids = entities_by_type.get(tgt_type, [])

        if not src_ids or not tgt_ids:
            continue

        for src_id in src_ids:
            for tgt_id in tgt_ids:
                relationships_list.append(
                    {
                        "source": src_id,
                        "relation": rel_name,
                        "target": tgt_id,
                        "confidence": conf,
                        "properties": props,
                    }
                )

    # Preserve other metadata keys but replace entities/relationships
    base_meta = {
        k: v
        for k, v in data.items()
        if k not in ("entities", "relationships")
    }
    return {
        **base_meta,
        "entities": entities_list,
        "relationships": relationships_list,
    }


def normalize_entities(raw_entities: Any) -> List[Dict[str, Any]]:
    """Repair entity entries based on schema in data/{graph}/config/schema_keys.json."""
    schema = require_schema_config()
    entity_schema = schema.get("entities", {}) or {}

    if isinstance(raw_entities, dict):
        raw_entities = [raw_entities]
    entities = raw_entities if isinstance(raw_entities, list) else []
    fixed: List[Dict[str, Any]] = []

    for ent in entities:
        if not isinstance(ent, dict):
            continue
        ent_type = str(ent.get("type", "") or "").strip()
        ent_schema = entity_schema.get(ent_type, {})
        attrs_schema = ent_schema.get("attributes", {}) or {}

        attrs = ent.get("attributes") if isinstance(ent.get("attributes"), dict) else {}
        for attr_name, attr_template in attrs_schema.items():
            attrs[attr_name] = _normalize_value_conf(
                attrs.get(attr_name),
                attr_template if isinstance(attr_template, dict) else {},
            )

        ent["attributes"] = attrs
        ent["confidence"] = _ensure_float(ent.get("confidence"), ent_schema.get("confidence", 0.0))

        # Preserve original synthetic IDs (e.g., "vtuber_1") here so that
        # relationships can be rewired first. The final step that overwrites
        # id ‚Üí name now occurs in normalize_document(), after relationship
        # endpoints have been updated.
        ent_id = ent.get("id") or ent.get("name") or ""
        ent["id"] = str(ent_id)
        ent["name"] = ent.get("name", "") or ""
        ent["type"] = ent_type

        fixed.append(ent)
    return fixed


def normalize_relationships(raw_rels: Any) -> List[Dict[str, Any]]:
    """Repair relationship entries based on schema in data/{graph}/config/schema_keys.json."""
    schema = require_schema_config()
    rel_schema = schema.get("relationships", {}) or {}

    if isinstance(raw_rels, dict):
        raw_rels = [raw_rels]
    rels = raw_rels if isinstance(raw_rels, list) else []
    fixed: List[Dict[str, Any]] = []

    for rel in rels:
        if not isinstance(rel, dict):
            continue
        rel_type = str(rel.get("relation", "") or "").strip()
        rel_cfg = rel_schema.get(rel_type, {})
        props_schema = rel_cfg.get("properties", {}) or {}

        props = rel.get("properties") if isinstance(rel.get("properties"), dict) else {}
        for prop_name, prop_template in props_schema.items():
            props[prop_name] = _normalize_value_conf(
                props.get(prop_name),
                prop_template if isinstance(prop_template, dict) else {},
            )

        rel["properties"] = props
        rel["confidence"] = _ensure_float(rel.get("confidence"), rel_cfg.get("confidence", 0.0))
        rel["source"] = rel.get("source", "") or ""
        rel["target"] = rel.get("target", "") or ""
        rel["relation"] = rel_type

        fixed.append(rel)
    return fixed


def normalize_document(data: dict) -> dict:
    """Apply schema-aware repairs to a single JSON document."""
    if not isinstance(data, dict):
        return {}

    data = dict(data)  # shallow copy to avoid mutating original

    # If this document is in schema-like format (entities/relationships as
    # type-level objects), convert it into a concrete graph-document first.
    if isinstance(data.get("entities"), dict) and isinstance(data.get("relationships"), dict):
        data = _convert_schema_like_to_graph_doc(data)

    entities = normalize_entities(data.get("entities"))
    relationships = normalize_relationships(data.get("relationships"))

    # Optional list-based structures emitted by Module 3 for some topics
    entities_list = data.get("entities_list")
    relationships_list = data.get("relationships_list")

    # ------------------------------------------------------------------
    # Step 1: Build mapping from synthetic IDs to human-readable names.
    #         We gather from both entities and entities_list if present.
    # ------------------------------------------------------------------
    id_to_name: Dict[str, str] = {}

    # From normalized entities
    for ent in entities:
        ent_id = str(ent.get("id") or "").strip()
        ent_name = str(ent.get("name") or "").strip()
        if ent_id and ent_name:
            id_to_name[ent_id] = ent_name

    # From entities_list (graph-style docs like VTuber)
    if isinstance(entities_list, list):
        for ent in entities_list:
            if not isinstance(ent, dict):
                continue
            ent_id = str(ent.get("id") or "").strip()
            ent_name = str(ent.get("name") or "").strip()
            if ent_id and ent_name:
                id_to_name[ent_id] = ent_name

    # ------------------------------------------------------------------
    # Step 2a: Rewrite relationship endpoints (relationships) using names.
    # ------------------------------------------------------------------
    for rel in relationships:
        if not isinstance(rel, dict):
            continue

        src = rel.get("source")
        tgt = rel.get("target")

        if isinstance(src, str) and src in id_to_name:
            rel["source"] = id_to_name[src]
        if isinstance(tgt, str) and tgt in id_to_name:
            rel["target"] = id_to_name[tgt]

    # ------------------------------------------------------------------
    # Step 2b: Rewrite relationship endpoints in relationships_list too.
    #          Example: source="vtuber_1" ‚Üí "Usada Pekora"
    #                   target="agency_2" ‚Üí "Hololive Production"
    # ------------------------------------------------------------------
    if isinstance(relationships_list, list):
        for rel in relationships_list:
            if not isinstance(rel, dict):
                continue
            src = rel.get("source")
            tgt = rel.get("target")
            if isinstance(src, str) and src in id_to_name:
                rel["source"] = id_to_name[src]
            if isinstance(tgt, str) and tgt in id_to_name:
                rel["target"] = id_to_name[tgt]

    # ------------------------------------------------------------------
    # Step 3: Overwrite entity IDs with their names, now that all
    #         relationship endpoints have been updated.
    #         Example: id="vtuber_1" ‚Üí "Usada Pekora"
    # ------------------------------------------------------------------
    for ent in entities:
        ent_name = ent.get("name")
        if isinstance(ent_name, str) and ent_name:
            ent["id"] = ent_name

    if isinstance(entities_list, list):
        for ent in entities_list:
            if not isinstance(ent, dict):
                continue
            ent_name = ent.get("name")
            if isinstance(ent_name, str) and ent_name:
                ent["id"] = ent_name

    data["entities"] = entities
    data["relationships"] = relationships
    if isinstance(entities_list, list):
        data["entities_list"] = entities_list
    if isinstance(relationships_list, list):
        data["relationships_list"] = relationships_list
    return data


def validate_file(path: Path, output_dir: Path):
    print(f"üîç Validating {path.name}...")
    try:
        text = path.read_text(encoding="utf-8")
        data = json.loads(text)
    except json.JSONDecodeError as e:
        print(f"‚ùå {path.name}: Invalid JSON ‚Äî {e}")
        return False

    fixed = normalize_document(data)
    out_path = output_dir / path.name
    out_path.write_text(json.dumps(fixed, indent=2, ensure_ascii=False), encoding="utf-8")
    print(f"‚úÖ {path.name}: Validated -> {out_path}")
    return True


def validate_all(target: Path, output_dir: Path):
    output_dir.mkdir(parents=True, exist_ok=True)

    if target.is_file():
        return validate_file(target, output_dir)
    if target.is_dir():
        files = [f for f in sorted(target.glob("*.json")) if f.name != "metadata_unknown.json"]
        if not files:
            print(f"No JSON files found in {target}")
            return False
        ok = [validate_file(f, output_dir) for f in files]
        print(f"\nSummary: {sum(ok)}/{len(files)} passed (and fixed if needed). Output dir: {output_dir}")
        return all(ok)

    print(f"Path not found: {target}")
    return False


# ---------------------------------------------------------------------
# CLI Entry
# ---------------------------------------------------------------------


def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(description="Validate and auto-repair extracted JSON files.")
    p.add_argument(
        "target",
        nargs="?",
        help="File or directory to validate (default: {base}/json).",
    )
    p.add_argument("--graph-name", help="Graph/topic name (uses data/{graph} as base).")
    p.add_argument("--data-location", help="Explicit data directory (overrides --graph-name).")
    p.add_argument("--schema-path", help="Path to schema_keys.json (default: {base}/config/schema_keys.json).")
    p.add_argument("--output-dir", help="Directory to write validated JSON (default: {base}/json_validated).")
    return p.parse_args()


if __name__ == "__main__":
    args = parse_args()
    base_dir = resolve_base_dir(args.graph_name, args.data_location, create=True)
    target_path = Path(args.target) if args.target else base_dir / "json"

    schema_path = resolve_schema_path(base_dir, args.schema_path)
    output_dir = Path(args.output_dir) if args.output_dir else base_dir / "json_validated"

    # If schema defines node_types (graph schema), skip validation‚Äîassume structured elsewhere
    try:
        schema_json = json.loads(schema_path.read_text(encoding="utf-8"))
        if isinstance(schema_json, dict) and "node_types" in schema_json:
            print(f"Schema uses node_types; skipping Module 4 validation for graph-style schema: {schema_path}")
            sys.exit(0)
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not parse schema at {schema_path}: {e}")

    configure_schema(schema_path)

    start = datetime.datetime.now()
    ok = validate_all(target_path, output_dir)
    print(f"\nCompleted in {(datetime.datetime.now() - start).total_seconds():.2f}s")
    sys.exit(0 if ok else 1)
